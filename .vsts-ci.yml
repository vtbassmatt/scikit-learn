
phases:

- phase: 'TestInUbuntu'
  queue:
    name: 'Hosted Linux Preview'
    parallel: 1
    matrix:
      # Python27:
      #   python.version: '2.7'
      # Python35:
      #   python.version: '3.5'
      Python36:
        conda: true
        python.version: '3.6'
        numpy.version: '1.14.2'
        scipy.version: '1.0.0'
        pandas.version: '0.20.3'
        cython.version: '0.26.1'
        pyamg.version: '3.3.2'
        pillow.version: '4.3.0'
        coverage: true
        run_flake8: false
        check_pytest_soft_dependency: true
        test_docstrings: true
      # Python37-dev:
      #   python.version: '>= 3.7.0a'
  
  variables:
    test_dir: '$($BUILD_BINARIESDIRECTORY/test)'
    omp_num_threads: 4
    openblas_num_threads: 4

  steps:

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '$(python.version)'
        architecture: 'x64'

    - script: |
        wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh
        MINICONDA_PATH=$BUILD_BINARIESDIRECTORY/miniconda
        chmod +x miniconda.sh && ./miniconda.sh -b -p $MINICONDA_PATH
        echo "##vso[task.setvariable variable=MINICONDA_PATH]$MINICONDA_PATH"
        export PATH=$MINICONDA_PATH/bin:$PATH
        conda update --yes conda

        TO_INSTALL="python=$PYTHON_VERSION pip pytest pytest-cov \
                    numpy=$NUMPY_VERSION scipy=$SCIPY_VERSION \
                    cython=$CYTHON_VERSION"

        if [[ "$INSTALL_MKL" == "true" ]]; then
            TO_INSTALL="$TO_INSTALL mkl"
        else
            TO_INSTALL="$TO_INSTALL nomkl"
        fi

        if [[ -n "$PANDAS_VERSION" ]]; then
            TO_INSTALL="$TO_INSTALL pandas=$PANDAS_VERSION"
        fi

        if [[ -n "$PYAMG_VERSION" ]]; then
            TO_INSTALL="$TO_INSTALL pyamg=$PYAMG_VERSION"
        fi

        if [[ -n "$PILLOW_VERSION" ]]; then
            TO_INSTALL="$TO_INSTALL pillow=$PILLOW_VERSION"
        fi

        conda create -n testenv --yes $TO_INSTALL
      displayName: 'Conda'
      condition: and(succeeded(), eq(variables['conda'], true))

    - script: |
        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        pip install coverage codecov
      displayName: 'Install coverage'
      condition: and(succeeded(), eq(variables['coverage'], true))

    - script: |
        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        conda install flake8 -y
      displayName: 'Install Flake8'
      condition: and(succeeded(), eq(variables['run_flake8'], true))

    - script: |
        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        pip install sphinx numpydoc
      displayName: 'Install doc tools'
      condition: and(succeeded(), eq(variables['test_docstrings'], true))

    - script: |
        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        python --version
        python -c "import numpy; print('numpy %s' % numpy.__version__)"
        python -c "import scipy; print('scipy %s' % scipy.__version__)"

        python setup.py develop
      displayName: 'Build'
    
    - script: |
        set -e

        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        python -c "import multiprocessing as mp; print('%d CPUs' % mp.cpu_count())"
        
        run_tests() {
          TEST_CMD="pytest --showlocals --durations=20 --pyargs"

          # Get into a temp directory to run test from the installed scikit-learn and
          # check if we do not leave artifacts
          mkdir -p $TEST_DIR
          # We need the setup.cfg for the pytest settings
          cp setup.cfg $TEST_DIR
          cd $TEST_DIR

          # Skip tests that require large downloads over the network to save bandwidth
          # usage as travis workers are stateless and therefore traditional local
          # disk caching does not work.
          export SKLEARN_SKIP_NETWORK_TESTS=1

          if [[ "$COVERAGE" == "true" ]]; then
              TEST_CMD="$TEST_CMD --cov sklearn"
          fi
          $TEST_CMD sklearn

          # Going back to git checkout folder needed to test documentation
          cd $OLDPWD

          make test-doc
        }

        # if [[ "$RUN_FLAKE8" == "true" ]]; then
        #     source build_tools/travis/flake8_diff.sh
        # fi

        if [[ "$SKIP_TESTS" != "true" ]]; then
            run_tests
        fi

        if [[ "$CHECK_PYTEST_SOFT_DEPENDENCY" == "true" ]]; then
            conda remove -y py pytest || pip uninstall -y py pytest
            if [[ "$COVERAGE" == "true" ]]; then
                # Need to append the coverage to the existing .coverage generated by
                # running the tests
                CMD="coverage run --append"
            else
                CMD="python"
            fi
            # .coverage from running the tests is in TEST_DIR
            cd $TEST_DIR
            $CMD -m sklearn.utils.tests.test_estimator_checks
            cd $OLDPWD
        fi
      displayName: 'Test'
    
    - script: |
        set -e

        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        if [[ "$COVERAGE" == "true" ]]; then
          # Need to run codecov from a git checkout, so we copy .coverage
          # from TEST_DIR where pytest has been run
          cp $TEST_DIR/.coverage $BUILD_SOURCESDIRECTORY
          cd $BUILD_SOURCESDIRECTORY
          # Ignore codecov failures as the codecov server is not
          # very reliable but we don't want travis to report a failure
          # in the github UI just because the coverage report failed to
          # be published.
          #codecov || echo "codecov upload failed"
        fi
      displayName: 'Post-success codecov upload'
      condition: succeeded()

    - task: PublishCodeCoverageResults@1
      inputs:
        summaryFileLocation: '**/.coverage'



phases:

- phase: 'TestInUbuntu'
  queue:
    name: 'Hosted Linux Preview'
    parallel: 1
    matrix:
      # Python27:
      #   python.version: '2.7'
      # Python35:
      #   python.version: '3.5'
      Python36:
        conda: true
        python.version: '3.6'
        numpy.version: '1.14.2'
        scipy.version: '1.0.0'
        pandas.version: '0.20.3'
        cython.version: '0.26.1'
        pyamg.version: '3.3.2'
        pillow.version: '4.3.0'
        coverage: true
        check_pytest_soft_dependency: true
        test_docstrings: true
      # Python37-dev:
      #   python.version: '>= 3.7.0a'
  
  variables:
    test_dir: '$($BUILD_BINARIESDIRECTORY/test)'
    omp_num_threads: 4
    openblas_num_threads: 4

  steps:

    - task: UsePythonVersion@0
      inputs:
        versionSpec: '$(python.version)'
        architecture: 'x64'

    # - script: python -m pip install --upgrade pip && pip install -r requirements.txt
    #   displayName: 'Install dependencies'
    
    - script: |
        wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh
        MINICONDA_PATH=$BUILD_BINARIESDIRECTORY/miniconda
        chmod +x miniconda.sh && ./miniconda.sh -b -p $MINICONDA_PATH
        echo "##vso[task.setvariable variable=MINICONDA_PATH]$MINICONDA_PATH"
        export PATH=$MINICONDA_PATH/bin:$PATH
        conda update --yes conda

        TO_INSTALL="python=$PYTHON_VERSION pip pytest pytest-cov \
                    numpy=$NUMPY_VERSION scipy=$SCIPY_VERSION \
                    cython=$CYTHON_VERSION"

        if [[ "$INSTALL_MKL" == "true" ]]; then
            TO_INSTALL="$TO_INSTALL mkl"
        else
            TO_INSTALL="$TO_INSTALL nomkl"
        fi

        if [[ -n "$PANDAS_VERSION" ]]; then
            TO_INSTALL="$TO_INSTALL pandas=$PANDAS_VERSION"
        fi

        if [[ -n "$PYAMG_VERSION" ]]; then
            TO_INSTALL="$TO_INSTALL pyamg=$PYAMG_VERSION"
        fi

        if [[ -n "$PILLOW_VERSION" ]]; then
            TO_INSTALL="$TO_INSTALL pillow=$PILLOW_VERSION"
        fi

        conda create -n testenv --yes $TO_INSTALL
        #source activate testenv
      displayName: 'Conda'
      condition: and(succeeded(), eq(variables['conda'], true))

    - script: |
        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        pip install coverage codecov
      displayName: 'Install coverage'
      condition: and(succeeded(), eq(variables['coverage'], true))

    # - script: 'pip install sphinx numpydoc'
    #   displayName: 'Install doc tools'
    #   condition: and(succeeded(), eq(variables['test_docstrings'], true))

    - script: |
        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        python --version
        python -c "import numpy; print('numpy %s' % numpy.__version__)"
        python -c "import scipy; print('scipy %s' % scipy.__version__)"

        python setup.py develop
      displayName: 'Build'
    
    - script: |
        set -e

        if [ -n "$MINICONDA_PATH" ]; then
          export PATH=$MINICONDA_PATH/bin:$PATH
          source activate testenv
        fi

        python -c "import multiprocessing as mp; print('%d CPUs' % mp.cpu_count())"
        
        run_tests() {
          TEST_CMD="pytest --showlocals --durations=20 --pyargs"

          # Get into a temp directory to run test from the installed scikit-learn and
          # check if we do not leave artifacts
          mkdir -p $TEST_DIR
          # We need the setup.cfg for the pytest settings
          cp setup.cfg $TEST_DIR
          cd $TEST_DIR

          # Skip tests that require large downloads over the network to save bandwidth
          # usage as travis workers are stateless and therefore traditional local
          # disk caching does not work.
          export SKLEARN_SKIP_NETWORK_TESTS=1

          if [[ "$COVERAGE" == "true" ]]; then
              TEST_CMD="$TEST_CMD --cov sklearn"
          fi
          $TEST_CMD sklearn

          # Going back to git checkout folder needed to test documentation
          cd $OLDPWD

          make test-doc
      }

      # if [[ "$RUN_FLAKE8" == "true" ]]; then
      #     source build_tools/travis/flake8_diff.sh
      # fi

      if [[ "$SKIP_TESTS" != "true" ]]; then
          run_tests
      fi

      if [[ "$CHECK_PYTEST_SOFT_DEPENDENCY" == "true" ]]; then
          conda remove -y py pytest || pip uninstall -y py pytest
          if [[ "$COVERAGE" == "true" ]]; then
              # Need to append the coverage to the existing .coverage generated by
              # running the tests
              CMD="coverage run --append"
          else
              CMD="python"
          fi
          # .coverage from running the tests is in TEST_DIR
          cd $TEST_DIR
          $CMD -m sklearn.utils.tests.test_estimator_checks
          cd $OLDPWD
      fi
      displayName: 'Test'

    # - script: pip install pytest && pytest tests --doctest-modules --junitxml=junit/test-results.xml
    #   displayName: 'pytest'

    # - task: PublishTestResults@2
    #   inputs:
    #     testResultsFiles: '**/test-results.xml'
    #     testRunTitle: 'Python $(python.version)'
